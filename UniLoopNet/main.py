#!/usr/bin/env python
import os
import torch
import numpy as np
from data_loader import create_multitask_data_loaders, debug_data_shapes
from layer import create
from UniLoopNet_train import CREATE_multitask_train

def main():
    # ========== é…ç½®å‚æ•° ==========
    config = {
        # æ•°æ®è·¯å¾„ - EPIä»»åŠ¡ (åŸæœ‰æ•°æ®)
        'epi_train_seq1_path': '/public/home/shenyin_wsb_2606/Third/EP1000/5000/EPL_B.npz',
        'epi_train_seq2_path': '/public/home/shenyin_wsb_2606/Third/EP1000/5000/EPR_B.npz', 
        'epi_test_seq1_path': '/public/home/shenyin_wsb_2606/Third/EP1000/5000/EPL_C.npz',
        'epi_test_seq2_path': '/public/home/shenyin_wsb_2606/Third/EP1000/5000/EPR_C.npz',
        
        # æ•°æ®è·¯å¾„ - EEIä»»åŠ¡ (æ–°å¢)
        'eei_train_seq1_path': '/public/home/shenyin_wsb_2606/Third/EE1000/5000/EEL_B.npz',
        'eei_train_seq2_path': '/public/home/shenyin_wsb_2606/Third/EE1000/5000/EER_B.npz',
        'eei_test_seq1_path': '/public/home/shenyin_wsb_2606/Third/EE1000/5000/EEL_C.npz',
        'eei_test_seq2_path': '/public/home/shenyin_wsb_2606/Third/EE1000/5000/EER_C.npz',
        
        # è®­ç»ƒå‚æ•°
        'batch_size': 24,
        'val_ratio': 0.1,
        'lr': 3e-5,
        'max_epoch': 300,
        'pre_epoch': 50,
        'seq_loss_weight': 1.0,
        
        # å¤šä»»åŠ¡æƒé‡ - åªä¿ç•™EPIå’ŒEEI
        'task_weights': {'epi': 1.0, 'eei': 1.0},
        
        # æ¨¡å‹å‚æ•°
        'channel1': 512,
        'channel2': 384,
        'channel3': 128,
        'channel4': 200,
        'channel5': 200,
        'embed_dim': 128,
        'seq_length': 5000,
        
        # å…¶ä»–
        'device': 'cuda:1' if torch.cuda.is_available() else 'cpu',
        'outdir': './results/',
        'random_state': 42
    }
    
    print("ğŸš€ å¼€å§‹EPI+EEIåŒä»»åŠ¡è®­ç»ƒ")
    print(f"ä½¿ç”¨è®¾å¤‡: {config['device']}")
    print(f"åºåˆ—é•¿åº¦: {config['seq_length']}")
    
    # ========== æ•°æ®åŠ è½½ ==========
    print("\nğŸ“Š åŠ è½½EPI+EEIåŒä»»åŠ¡æ•°æ®...")
    task_loaders, task_val_labels, task_test_labels = create_multitask_data_loaders(
        # EPIä»»åŠ¡æ•°æ®è·¯å¾„
        epi_train_seq1_path=config['epi_train_seq1_path'],
        epi_train_seq2_path=config['epi_train_seq2_path'],
        epi_test_seq1_path=config['epi_test_seq1_path'],
        epi_test_seq2_path=config['epi_test_seq2_path'],
        
        # EEIä»»åŠ¡æ•°æ®è·¯å¾„
        eei_train_seq1_path=config['eei_train_seq1_path'],
        eei_train_seq2_path=config['eei_train_seq2_path'],
        eei_test_seq1_path=config['eei_test_seq1_path'],
        eei_test_seq2_path=config['eei_test_seq2_path'],
        
        batch_size=config['batch_size'],
        val_ratio=config['val_ratio'],
        random_state=config['random_state']
    )
    
    # è°ƒè¯•æ•°æ®å½¢çŠ¶
    debug_data_shapes(task_loaders)
    
    # ========== æ¨¡å‹åˆ›å»º ==========
    print("\nğŸ§  åˆ›å»ºEPI+EEIåŒä»»åŠ¡æ¨¡å‹...")
    model = create(
        channel1=config['channel1'],
        channel2=config['channel2'],
        channel3=config['channel3'],
        channel4=config['channel4'],
        channel5=config['channel5'],
    )
    
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # ========== å¼€å§‹è®­ç»ƒ ==========
    print("\nğŸ‹ï¸ å¼€å§‹EPI+EEIåŒä»»åŠ¡è®­ç»ƒ...")
    CREATE_multitask_train(
        clf=model,
        train_loader=task_loaders,
        valid_loader=task_loaders,
        test_loader=task_loaders,
        valid_labels=task_val_labels,
        test_labels=task_test_labels,
        lr=config['lr'],
        max_epoch=config['max_epoch'],
        pre_epoch=config['pre_epoch'],
        seq_loss_weight=config['seq_loss_weight'],
        task_weights=config['task_weights'],
        outdir=config['outdir'],
        device=config['device']
    )


if __name__ == "__main__":
    main()