#!/usr/bin/env python
import os
import torch
import numpy as np
import pandas as pd
import json
from data_loader import UniLoopNet_multitask_data_loaders, create_ctcf_data_loaders
from layer import create
from UniLoopNet_train import CREATE_multitask_train
from continual_learning import continual_learning_train, train_single_task_ctcf


def main():
    # ========== é…ç½®å‚æ•° ==========
    config = {
        # åŸå§‹ä»»åŠ¡æ•°æ®è·¯å¾„ - EPIä»»åŠ¡
        'epi_train_seq1_path': '/public/home/shenyin_wsb_2606/Third/EP1000/5000/EPL_B.npz',
        'epi_train_seq2_path': '/public/home/shenyin_wsb_2606/Third/EP1000/5000/EPR_B.npz', 
        'epi_test_seq1_path': '/public/home/shenyin_wsb_2606/Third/EP1000/5000/EPL_C.npz',
        'epi_test_seq2_path': '/public/home/shenyin_wsb_2606/Third/EP1000/5000/EPR_C.npz',
        
        # åŸå§‹ä»»åŠ¡æ•°æ®è·¯å¾„ - EEIä»»åŠ¡
        'eei_train_seq1_path': '/public/home/shenyin_wsb_2606/Third/EE1000/5000/EEL_B.npz',
        'eei_train_seq2_path': '/public/home/shenyin_wsb_2606/Third/EE1000/5000/EER_B.npz',
        'eei_test_seq1_path': '/public/home/shenyin_wsb_2606/Third/EE1000/5000/EEL_C.npz',
        'eei_test_seq2_path': '/public/home/shenyin_wsb_2606/Third/EE1000/5000/EER_C.npz',
        
        
        'ctcf_train_seq1_path': '/public/home/shenyin_wsb_2606/Third/CTCF/CTCFL_B.npz',
        'ctcf_train_seq2_path': '/public/home/shenyin_wsb_2606/Third/CTCF/CTCFR_B.npz',
        'ctcf_test_seq1_path': '/public/home/shenyin_wsb_2606/Third/CTCF/CTCFL_C.npz',
        'ctcf_test_seq2_path': '/public/home/shenyin_wsb_2606/Third/CTCF/CTCFR_C.npz',
        
        # # æ–°ä»»åŠ¡æ•°æ®è·¯å¾„ - CTCFä»»åŠ¡ï¼ˆéœ€è¦æ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹ï¼‰
        # 'ctcf_train_seq1_path': '/public/home/shenyin_wsb_2606/Third/ctcf/1000/ctcfL_B.npz',
        # 'ctcf_train_seq2_path': '/public/home/shenyin_wsb_2606/Third/ctcf/1000/ctcfR_B.npz',
        # 'ctcf_test_seq1_path': '/public/home/shenyin_wsb_2606/Third/ctcf/1000/ctcfL_C.npz',
        # 'ctcf_test_seq2_path': '/public/home/shenyin_wsb_2606/Third/ctcf/1000/ctcfR_C.npz',
        
        # è®­ç»ƒå‚æ•°
        'batch_size': 24,
        'val_ratio': 0.1,
        'lr': 3e-5,
        'max_epoch': 300,
        'pre_epoch': 50,
        'seq_loss_weight': 1.0,
        
        # å¤šä»»åŠ¡æƒé‡
        'task_weights': {'epi': 1.0, 'eei': 1.0},
        
        # æŒç»­å­¦ä¹ å‚æ•°
        'cl_lr': 1e-5,
        'cl_max_epoch': 100,
        'sampling_ratios': [0.0, 0.02,0.2,1.0],
        'use_ewc': True,
        'lambda_ewc': 1000,
        
        # CTCFæ•°æ®å¡«å……å‚æ•°
        'ctcf_target_length': 5000,  # ç›®æ ‡é•¿åº¦ï¼Œä¸EPI/EEIä¿æŒä¸€è‡´
        'ctcf_original_length': 1000,  # CTCFåŸå§‹é•¿åº¦
        'padding_strategy': 'symmetric',  # å¡«å……ç­–ç•¥ï¼š'symmetric', 'zero', 'edge'
        
        # æ¨¡å‹å‚æ•°
        'channel1': 512,
        'channel2': 384,
        'channel3': 128,
        'channel4': 200,
        'channel5': 200,
        'embed_dim': 128,
        'seq_length': 5000,
        
        # å…¶ä»–
        'device': 'cuda:0' if torch.cuda.is_available() else 'cpu',
        'outdir': './continual_learning_results/',
        'random_state': 42
    }
    
    print("ğŸš€ å¼€å§‹EPI+EEIåŒä»»åŠ¡é¢„è®­ç»ƒ + CTCFæŒç»­å­¦ä¹ å®éªŒ")
    print(f"ä½¿ç”¨è®¾å¤‡: {config['device']}")
    print(f"è¾“å‡ºç›®å½•: {config['outdir']}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config['outdir'], exist_ok=True)
    os.makedirs(os.path.join(config['outdir'], 'checkpoints'), exist_ok=True)
    os.makedirs(os.path.join(config['outdir'], 'results'), exist_ok=True)
    
    # ========== æ­¥éª¤1: é¢„è®­ç»ƒEPI+EEIåŒä»»åŠ¡æ¨¡å‹ ==========
    print(f"\n{'='*80}")
    print("æ­¥éª¤1: é¢„è®­ç»ƒEPI+EEIåŒä»»åŠ¡æ¨¡å‹")
    print(f"{'='*80}")
    
    # åŠ è½½åŸå§‹ä»»åŠ¡æ•°æ®
    print("åŠ è½½EPI+EEIåŒä»»åŠ¡æ•°æ®...")
    task_loaders, task_val_labels, task_test_labels = create_multitask_data_loaders(
        epi_train_seq1_path=config['epi_train_seq1_path'],
        epi_train_seq2_path=config['epi_train_seq2_path'],
        epi_test_seq1_path=config['epi_test_seq1_path'],
        epi_test_seq2_path=config['epi_test_seq2_path'],
        
        eei_train_seq1_path=config['eei_train_seq1_path'],
        eei_train_seq2_path=config['eei_train_seq2_path'],
        eei_test_seq1_path=config['eei_test_seq1_path'],
        eei_test_seq2_path=config['eei_test_seq2_path'],
        
        batch_size=config['batch_size'],
        val_ratio=config['val_ratio'],
        random_state=config['random_state']
    )
    
    # åˆ›å»ºæ¨¡å‹
    print("åˆ›å»ºEPI+EEI+CTCFå¤šä»»åŠ¡æ¨¡å‹...")
    model = create(
        channel1=config['channel1'],
        channel2=config['channel2'],
        channel3=config['channel3'],
        channel4=config['channel4'],
        channel5=config['channel5'],
        embed_dim=config['embed_dim']
    )
    
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # é¢„è®­ç»ƒEPI+EEIä»»åŠ¡
    print("å¼€å§‹é¢„è®­ç»ƒEPI+EEIåŒä»»åŠ¡...")
    pretrain_outdir = os.path.join(config['outdir'], 'pretrain')
    os.makedirs(pretrain_outdir, exist_ok=True)
    
    # CREATE_multitask_train(
    #     clf=model,
    #     train_loader=task_loaders,
    #     valid_loader=task_loaders,
    #     test_loader=task_loaders,
    #     valid_labels=task_val_labels,
    #     test_labels=task_test_labels,
    #     lr=config['lr'],
    #     max_epoch=config['max_epoch'],
    #     pre_epoch=config['pre_epoch'],
    #     seq_loss_weight=config['seq_loss_weight'],
    #     task_weights=config['task_weights'],
    #     outdir=pretrain_outdir,
    #     device=config['device']
    # )
    
    # åŠ è½½æœ€ä½³é¢„è®­ç»ƒæ¨¡å‹
    pretrain_model_path = os.path.join(pretrain_outdir, 'checkpoint', 'best_model.pth')
    if os.path.exists(pretrain_model_path):
        print("åŠ è½½æœ€ä½³é¢„è®­ç»ƒæ¨¡å‹...")
        checkpoint = torch.load(pretrain_model_path, map_location=config['device'])
        model.load_state_dict(checkpoint['model'])
        print(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æˆåŠŸ (Epoch {checkpoint['epoch']}, AUC: {checkpoint['val_avg_auc']:.4f})")
    else:
        print("è­¦å‘Š: æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨å½“å‰æ¨¡å‹ç»§ç»­...")
    
    # ========== æ­¥éª¤2: åŠ è½½CTCFæ•°æ® ==========
    print(f"\n{'='*80}")
    print("æ­¥éª¤2: åŠ è½½CTCFä»»åŠ¡æ•°æ®")
    print(f"{'='*80}")
    
    # åŠ è½½CTCFæ•°æ®
    print("åŠ è½½CTCFä»»åŠ¡æ•°æ®...")
    ctcf_loaders = create_ctcf_data_loaders(
        ctcf_train_seq1_path=config['ctcf_train_seq1_path'],
        ctcf_train_seq2_path=config['ctcf_train_seq2_path'],
        ctcf_test_seq1_path=config['ctcf_test_seq1_path'],
        ctcf_test_seq2_path=config['ctcf_test_seq2_path'],
        sampling_ratios=config['sampling_ratios'],
        batch_size=config['batch_size'],
        val_ratio=config['val_ratio'],
        random_state=config['random_state'],
        target_length=config['ctcf_target_length'],
        original_length=config['ctcf_original_length'],
        padding_strategy=config['padding_strategy']
    )
    
    # ========== æ­¥éª¤3: æŒç»­å­¦ä¹ å®éªŒ ==========
    print(f"\n{'='*80}")
    print("æ­¥éª¤3: æŒç»­å­¦ä¹ å®éªŒ")
    print(f"{'='*80}")
    
    # ä¿å­˜ç»“æœ
    cl_results = []
    single_task_results = []
    
    # æ¨¡å‹é…ç½®ï¼ˆç”¨äºå•ä»»åŠ¡è®­ç»ƒï¼‰
    model_config = {
        'channel1': config['channel1'],
        'channel2': config['channel2'],
        'channel3': config['channel3'],
        'channel4': config['channel4'],
        'channel5': config['channel5'],
        'embed_dim': config['embed_dim']
    }
    
    for sampling_ratio in config['sampling_ratios']:
        print(f"\n{'-'*60}")
        print(f"å®éªŒé‡‡æ ·ç‡: {sampling_ratio*100}%")
        print(f"{'-'*60}")
        
        # ä¸ºæ¯ä¸ªé‡‡æ ·ç‡åˆ›å»ºæ¨¡å‹å‰¯æœ¬
        model_copy = create(**model_config)
        model_copy.load_state_dict(model.state_dict())
        model_copy = model_copy.to(config['device'])
        
        # æŒç»­å­¦ä¹ è®­ç»ƒ
        cl_result = continual_learning_train(
            model=model_copy,
            ctcf_loaders=ctcf_loaders,
            epi_test_loader=task_loaders['epi']['test'],
            eei_test_loader=task_loaders['eei']['test'],
            epi_test_labels=task_test_labels['epi'],
            eei_test_labels=task_test_labels['eei'],
            sampling_ratio=sampling_ratio,
            lr=config['cl_lr'],
            max_epoch=config['cl_max_epoch'],
            device=config['device'],
            outdir=config['outdir'],
            use_ewc=config['use_ewc'],
            lambda_ewc=config['lambda_ewc']
        )
        
        cl_result['sampling_ratio'] = sampling_ratio
        cl_result['method'] = 'continual_learning'
        cl_results.append(cl_result)
        
        # å•ä»»åŠ¡è®­ç»ƒï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        if sampling_ratio > 0:  # 0%é‡‡æ ·ç‡æ— æ³•è®­ç»ƒå•ä»»åŠ¡æ¨¡å‹
            single_task_result = train_single_task_ctcf(
                ctcf_loaders=ctcf_loaders,
                sampling_ratio=sampling_ratio,
                model_config=model_config,
                lr=config['cl_lr'] * 10,  # å•ä»»åŠ¡ä½¿ç”¨æ›´é«˜å­¦ä¹ ç‡
                max_epoch=config['cl_max_epoch'],
                device=config['device'],
                outdir=config['outdir']
            )
            
            single_task_result['sampling_ratio'] = sampling_ratio
            single_task_result['method'] = 'single_task'
            single_task_results.append(single_task_result)
    
    # ========== æ­¥éª¤4: ç»“æœåˆ†æ ==========
    print(f"\n{'='*80}")
    print("æ­¥éª¤4: å®éªŒç»“æœåˆ†æ")
    print(f"{'='*80}")
    
    # è½¬æ¢ä¸ºDataFrame
    cl_df = pd.DataFrame(cl_results)
    single_task_df = pd.DataFrame(single_task_results)
    
    # æ‰“å°ç»“æœè¡¨æ ¼
    print("\næŒç»­å­¦ä¹ ç»“æœ:")
    print("="*120)
    print(f"{'é‡‡æ ·ç‡':<8} {'CTCF AUC':<12} {'EPI AUC':<10} {'EEI AUC':<10} {'EPIé—å¿˜ç‡':<12} {'EEIé—å¿˜ç‡':<12}")
    print("="*120)
    
    for _, row in cl_df.iterrows():
        print(f"{row['sampling_ratio']*100:>6.0f}%  "
              f"{row['ctcf_auc']:>10.4f}  "
              f"{row['epi_auc']:>8.4f}  "
              f"{row['eei_auc']:>8.4f}  "
              f"{row['epi_forgetting']:>10.4f}  "
              f"{row['eei_forgetting']:>10.4f}")
    
    print("\nå•ä»»åŠ¡è®­ç»ƒç»“æœ:")
    print("="*40)
    print(f"{'é‡‡æ ·ç‡':<8} {'CTCF AUC':<12}")
    print("="*40)
    
    for _, row in single_task_df.iterrows():
        print(f"{row['sampling_ratio']*100:>6.0f}%  {row['ctcf_auc']:>10.4f}")
    
    # å¯¹æ¯”åˆ†æ
    print("\næŒç»­å­¦ä¹  vs å•ä»»åŠ¡è®­ç»ƒå¯¹æ¯”:")
    print("="*60)
    print(f"{'é‡‡æ ·ç‡':<8} {'æŒç»­å­¦ä¹ ':<12} {'å•ä»»åŠ¡':<10} {'æå‡':<10}")
    print("="*60)
    
    for cl_row in cl_results:
        if cl_row['sampling_ratio'] > 0:
            single_row = next((x for x in single_task_results if x['sampling_ratio'] == cl_row['sampling_ratio']), None)
            if single_row:
                improvement = cl_row['ctcf_auc'] - single_row['ctcf_auc']
                print(f"{cl_row['sampling_ratio']*100:>6.0f}%  "
                      f"{cl_row['ctcf_auc']:>10.4f}  "
                      f"{single_row['ctcf_auc']:>8.4f}  "
                      f"{improvement:>+8.4f}")
    
    # ä¿å­˜ç»“æœ
    results_file = os.path.join(config['outdir'], 'results', 'experiment_results.json')
    with open(results_file, 'w') as f:
        json.dump({
            'config': config,
            'continual_learning_results': cl_results,
            'single_task_results': single_task_results,
        }, f, indent=2)
    
    # ä¿å­˜CSV
    cl_df.to_csv(os.path.join(config['outdir'], 'results', 'continual_learning_results.csv'), index=False)
    if not single_task_df.empty:
        single_task_df.to_csv(os.path.join(config['outdir'], 'results', 'single_task_results.csv'), index=False)
    
    print(f"\nå®éªŒå®Œæˆ! ç»“æœä¿å­˜åœ¨: {config['outdir']}")
    print(f"è¯¦ç»†ç»“æœæ–‡ä»¶: {results_file}")


if __name__ == "__main__":
    main()